[English](README.md) Â· [Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](i18n/README.ar.md) Â· [EspaÃ±ol](i18n/README.es.md) Â· [FranÃ§ais](i18n/README.fr.md) Â· [æ—¥æœ¬èª](i18n/README.ja.md) Â· [í•œêµ­ì–´](i18n/README.ko.md) Â· [Tiáº¿ng Viá»‡t](i18n/README.vi.md) Â· [ä¸­æ–‡ (ç®€ä½“)](i18n/README.zh-Hans.md) Â· [ä¸­æ–‡ï¼ˆç¹é«”ï¼‰](i18n/README.zh-Hant.md) Â· [Deutsch](i18n/README.de.md) Â· [Ğ ÑƒÑÑĞºĞ¸Ğ¹](i18n/README.ru.md)


# Organoid Segmentation (Web + CLI)

![Python](https://img.shields.io/badge/Python-3.x-blue.svg)
![Framework](https://img.shields.io/badge/Backend-Tornado-009688.svg)
![AI](https://img.shields.io/badge/OpenAI-Vision%20Segmentation-412991.svg)
![Status](https://img.shields.io/badge/README-First%20Complete%20Draft-success.svg)
![Interface](https://img.shields.io/badge/UI-Web%20%2B%20CLI-0ea5e9)
![Outputs](https://img.shields.io/badge/Artifacts-Overlay%20%7C%20Mask%20%7C%20JSON-f97316)
![PWA](https://img.shields.io/badge/PWA-Minimal%20Support-22c55e)

A Python application for segmenting organoids in microscopy images using OpenAI vision-capable models.

This repository includes:
- A Tornado web server with upload UI.
- A CLI workflow for batch or scripted use.
- Polygon extraction, mask generation, and annotated image rendering.
- Minimal PWA support (manifest + service worker cache for core static assets).

## ğŸ” Overview

The app accepts an input microscopy image, sends it to an OpenAI model with a strict JSON schema prompt, and returns a single polygon tracing the organoid boundary.

### ğŸ“Œ At a Glance

| Area | Details |
|---|---|
| Input | Microscopy image |
| Core output | Organoid polygon (`x, y` points) |
| Derived files | Annotated overlay PNG, binary mask PNG, polygon JSON |
| Access modes | Web UI, CLI, direct API call |
| Backend | Tornado (`server.py`) |
| AI path | OpenAI Responses API first, Chat Completions fallback |

Generated artifacts:
- `*_annotated.png`: source image with semi-transparent red overlay.
- `*_mask.png`: binary organoid mask.
- `*_polygon.json`: structured output (`width`, `height`, `polygon`, `confidence`).

Primary runtime files:
- `server.py`: web app + API routes.
- `organoid_segmenter.py`: segmentation and image/mask output logic.
- `segment_organoid.py`: CLI wrapper.

## âœ¨ Features

- Web UI at `http://localhost:8888` for quick interactive segmentation.
- REST-like endpoint `POST /api/segment` with multipart upload support.
- Configurable model name from UI and CLI (`gpt-4o-2024-08-06` default).
- Validation and clamping of polygon points to image bounds.
- Automatic output directory creation (`uploads/`, `outputs/`).
- OpenAI Responses API first, Chat Completions fallback in code path.
- Service worker support for caching core static files.

## ğŸ—‚ï¸ Project Structure

```text
Yinghan/
â”œâ”€ organoid_segmenter.py          # Core segmentation logic and output rendering
â”œâ”€ segment_organoid.py            # CLI entrypoint
â”œâ”€ server.py                      # Tornado server + API
â”œâ”€ requirements.txt               # Python dependencies
â”œâ”€ templates/
â”‚  â””â”€ index.html                  # Web UI shell
â”œâ”€ static/
â”‚  â”œâ”€ app.js                      # Frontend upload + result rendering logic
â”‚  â”œâ”€ styles.css                  # UI styles
â”‚  â”œâ”€ manifest.json               # PWA manifest
â”‚  â””â”€ sw.js                       # Service worker cache logic
â”œâ”€ i18n/                          # Localized README files (planned/generated by pipeline)
â”œâ”€ uploads/                       # Runtime upload storage (gitignored)
â”œâ”€ outputs/                       # Runtime segmentation outputs (gitignored, created at runtime)
â””â”€ .auto-readme-work/             # README generation pipeline context/artifacts
```

## âœ… Prerequisites

- Python 3.10+ (3.x required; 3.11 recommended).
- OpenAI API key with access to a vision-capable model.
- Network access from runtime environment to OpenAI APIs.

## âš™ï¸ Installation

```bash
git clone <your-repo-url>
cd Yinghan

python -m venv .venv
source .venv/bin/activate  # Windows: .venv\\Scripts\\activate

pip install -r requirements.txt
```

Set your API key:

```bash
export OPENAI_API_KEY="your_api_key_here"  # Windows PowerShell: $env:OPENAI_API_KEY="your_api_key_here"
```

## ğŸš€ Usage

### ğŸŒ Run Web App

```bash
python server.py
```

Open:

```text
http://localhost:8888
```

Web flow:
1. Choose an image.
2. Optionally change model in the input field.
3. Click **Segment**.
4. Review overlay, annotated image, and mask.

### ğŸ§ª Run CLI

```bash
python segment_organoid.py /path/to/image.jpg
```

Optional arguments:

```bash
python segment_organoid.py /path/to/image.jpg --out-dir outputs --model gpt-4o-2024-08-06
```

CLI prints output paths and a summary containing image dimensions and number of polygon points.

### ğŸ”Œ Call API Directly

```bash
curl -X POST http://localhost:8888/api/segment \
  -F "image=@/path/to/image.jpg" \
  -F "model=gpt-4o-2024-08-06"
```

Example response shape:

```json
{
  "width": 1024,
  "height": 1024,
  "polygon": [[100.0, 120.0], [110.0, 125.0]],
  "confidence": 0.92,
  "annotated_url": "/outputs/example_annotated.png",
  "mask_url": "/outputs/example_mask.png",
  "json_url": "/outputs/example_polygon.json",
  "upload_url": "/uploads/upload.jpg"
}
```

## ğŸ› ï¸ Configuration

Current configurable parameters from code:

- `model`:
  - Default: `gpt-4o-2024-08-06`
  - Settable via web form input or CLI `--model`
- `out_dir`:
  - CLI option `--out-dir` (default `outputs`)
  - Server uses `outputs/` internally

Environment variables:
- `OPENAI_API_KEY` (required).

Assumptions:
- `OpenAI()` client uses environment-based credentials.
- No custom base URL or org/project settings are required unless your OpenAI account setup needs them.

## ğŸ§¾ Examples

### ğŸ Programmatic Python Usage

```python
from organoid_segmenter import segment_organoid

result = segment_organoid(
    image_path="sample.jpg",
    out_dir="outputs",
    model="gpt-4o-2024-08-06",
)

print(result.annotated_path)
print(result.mask_path)
print(result.json_path)
print(result.confidence)
```

### ğŸ“„ Inspect Polygon JSON

```bash
cat outputs/<name>_polygon.json
```

### ğŸ§± Typical Output Files

```text
outputs/
â”œâ”€ <base>_<timestamp>_annotated.png
â”œâ”€ <base>_<timestamp>_mask.png
â””â”€ <base>_<timestamp>_polygon.json
```

## ğŸ§  Development Notes

- Backend framework: Tornado (`server.py`).
- Frontend stack: static HTML/CSS/JS (`templates/index.html`, `static/app.js`).
- Service worker registers on page load and caches core assets listed in `static/sw.js`.
- Polygon validation ensures at least 3 points and clamps to image boundaries.
- Output generation uses Pillow (`PIL.Image`, `ImageDraw`).

Local development tips:

```bash
# Run server
python server.py

# Run CLI against an existing image
python segment_organoid.py 6f1e1874eacffe1dbae0393f48811e74.jpg
```

## ğŸ©º Troubleshooting

- `openai.AuthenticationError` or similar:
  - Verify `OPENAI_API_KEY` is set in the shell running Python.
- `Model response did not contain valid JSON`:
  - Try a different model or re-run; fallback parsing is implemented but malformed output can still fail.
- `Polygon must contain at least 3 points`:
  - The model returned an invalid polygon; retry with a clearer image.
- UI loads but segmentation fails:
  - Check server logs for exception type returned by `/api/segment`.
- `ModuleNotFoundError`:
  - Reinstall dependencies with `pip install -r requirements.txt` in the active environment.

## ğŸ›£ï¸ Roadmap

Potential next steps for this repository:

1. Add automated tests for polygon validation and output generation.
2. Add CI (lint, type checks, and smoke tests).
3. Add batch-mode CLI for directory-level processing.
4. Support multiple object masks or instance segmentation output.
5. Add Dockerfile and deployment documentation.
6. Add benchmark examples and sample datasets with expected outputs.
7. Finalize multilingual README files under `i18n/`.

## ğŸ¤ Contributing

Contributions are welcome.

Recommended workflow:

1. Fork the repo and create a feature branch.
2. Make focused changes with clear commit messages.
3. Validate manual web + CLI flows locally.
4. Open a pull request describing behavior changes and test evidence.

Suggested contribution areas:
- Better prompt design for more stable polygon extraction.
- Improved frontend visualization (zoom/pan, contour smoothing).
- Test harnesses and reproducible sample fixtures.
- Documentation and localization improvements.

## ğŸ“„ License

No license file is currently present in this repository.

Assumption: all rights are reserved by default until a license is explicitly added.

If you plan to share or distribute this project, add a `LICENSE` file and update this section.
