[English](../README.md) · [العربية](README.ar.md) · [Español](README.es.md) · [Français](README.fr.md) · [日本語](README.ja.md) · [한국어](README.ko.md) · [Tiếng Việt](README.vi.md) · [中文 (简体)](README.zh-Hans.md) · [中文（繁體）](README.zh-Hant.md) · [Deutsch](README.de.md) · [Русский](README.ru.md)


# オルガノイド分割（Web + CLI）

![Python](https://img.shields.io/badge/Python-3.x-blue.svg)
![Framework](https://img.shields.io/badge/Backend-Tornado-009688.svg)
![AI](https://img.shields.io/badge/OpenAI-Vision%20Segmentation-412991.svg)
![Status](https://img.shields.io/badge/README-First%20Complete%20Draft-success.svg)
![Interface](https://img.shields.io/badge/UI-Web%20%2B%20CLI-0ea5e9)
![Outputs](https://img.shields.io/badge/Artifacts-Overlay%20%7C%20Mask%20%7C%20JSON-f97316)
![PWA](https://img.shields.io/badge/PWA-Minimal%20Support-22c55e)

OpenAI のビジョン対応モデルを使用して、顕微鏡画像内のオルガノイドを分割する Python アプリケーションです。

このリポジトリには次の内容が含まれます。
- アップロード UI を備えた Tornado Web サーバー。
- バッチ処理やスクリプト利用向けの CLI ワークフロー。
- ポリゴン抽出、マスク生成、注釈付き画像レンダリング。
- 最小限の PWA 対応（マニフェスト + コア静的アセット向けサービスワーカーキャッシュ）。

## 🔍 概要

このアプリは入力された顕微鏡画像を受け取り、厳密な JSON スキーマを指定したプロンプトとともに OpenAI モデルへ送信し、オルガノイド境界をトレースする単一のポリゴンを返します。

### 📌 ひと目でわかる仕様

| 項目 | 詳細 |
|---|---|
| 入力 | 顕微鏡画像 |
| コア出力 | オルガノイドポリゴン（`x, y` 点列） |
| 派生ファイル | 注釈オーバーレイ PNG、2値マスク PNG、ポリゴン JSON |
| 利用方法 | Web UI、CLI、直接 API 呼び出し |
| バックエンド | Tornado（`server.py`） |
| AI 経路 | OpenAI Responses API 優先、Chat Completions フォールバック |

生成される成果物:
- `*_annotated.png`: 半透明の赤オーバーレイを重ねた元画像。
- `*_mask.png`: オルガノイドの 2値マスク。
- `*_polygon.json`: 構造化出力（`width`, `height`, `polygon`, `confidence`）。

主要な実行時ファイル:
- `server.py`: Web アプリ + API ルート。
- `organoid_segmenter.py`: 分割処理と画像/マスク出力ロジック。
- `segment_organoid.py`: CLI ラッパー。

## ✨ 機能

- `http://localhost:8888` で、素早く対話的に分割できる Web UI。
- multipart アップロード対応の REST 風エンドポイント `POST /api/segment`。
- UI と CLI の両方でモデル名を設定可能（デフォルト `gpt-4o-2024-08-06`）。
- ポリゴン点を画像境界内に検証・クランプ。
- 出力ディレクトリを自動作成（`uploads/`, `outputs/`）。
- コード経路で OpenAI Responses API を優先し、Chat Completions へフォールバック。
- コア静的ファイルをキャッシュするサービスワーカー対応。

## 🗂️ プロジェクト構成

```text
Yinghan/
├─ organoid_segmenter.py          # Core segmentation logic and output rendering
├─ segment_organoid.py            # CLI entrypoint
├─ server.py                      # Tornado server + API
├─ requirements.txt               # Python dependencies
├─ templates/
│  └─ index.html                  # Web UI shell
├─ static/
│  ├─ app.js                      # Frontend upload + result rendering logic
│  ├─ styles.css                  # UI styles
│  ├─ manifest.json               # PWA manifest
│  └─ sw.js                       # Service worker cache logic
├─ i18n/                          # Localized README files (planned/generated by pipeline)
├─ uploads/                       # Runtime upload storage (gitignored)
├─ outputs/                       # Runtime segmentation outputs (gitignored, created at runtime)
└─ .auto-readme-work/             # README generation pipeline context/artifacts
```

## ✅ 前提条件

- Python 3.10+（3.x 必須、3.11 推奨）。
- ビジョン対応モデルへアクセス可能な OpenAI API キー。
- 実行環境から OpenAI API へ到達できるネットワーク接続。

## ⚙️ インストール

```bash
git clone <your-repo-url>
cd Yinghan

python -m venv .venv
source .venv/bin/activate  # Windows: .venv\\Scripts\\activate

pip install -r requirements.txt
```

API キーを設定します:

```bash
export OPENAI_API_KEY="your_api_key_here"  # Windows PowerShell: $env:OPENAI_API_KEY="your_api_key_here"
```

## 🚀 使い方

### 🌐 Web アプリを実行

```bash
python server.py
```

開く URL:

```text
http://localhost:8888
```

Web の手順:
1. 画像を選択します。
2. 必要に応じて入力欄でモデルを変更します。
3. **Segment** をクリックします。
4. オーバーレイ、注釈画像、マスクを確認します。

### 🧪 CLI を実行

```bash
python segment_organoid.py /path/to/image.jpg
```

任意引数:

```bash
python segment_organoid.py /path/to/image.jpg --out-dir outputs --model gpt-4o-2024-08-06
```

CLI は出力パスと、画像サイズ・ポリゴン点数を含むサマリーを表示します。

### 🔌 API を直接呼び出す

```bash
curl -X POST http://localhost:8888/api/segment \
  -F "image=@/path/to/image.jpg" \
  -F "model=gpt-4o-2024-08-06"
```

レスポンス例:

```json
{
  "width": 1024,
  "height": 1024,
  "polygon": [[100.0, 120.0], [110.0, 125.0]],
  "confidence": 0.92,
  "annotated_url": "/outputs/example_annotated.png",
  "mask_url": "/outputs/example_mask.png",
  "json_url": "/outputs/example_polygon.json",
  "upload_url": "/uploads/upload.jpg"
}
```

## 🛠️ 設定

現在コードから設定可能なパラメータ:

- `model`:
  - デフォルト: `gpt-4o-2024-08-06`
  - Web フォーム入力または CLI `--model` で設定可能
- `out_dir`:
  - CLI オプション `--out-dir`（デフォルト `outputs`）
  - サーバー内部では `outputs/` を使用

環境変数:
- `OPENAI_API_KEY`（必須）。

前提:
- `OpenAI()` クライアントは環境変数ベースの認証情報を使用します。
- OpenAI アカウント構成で必要な場合を除き、カスタム base URL や org/project 設定は不要です。

## 🧾 例

### 🐍 Python からのプログラム利用

```python
from organoid_segmenter import segment_organoid

result = segment_organoid(
    image_path="sample.jpg",
    out_dir="outputs",
    model="gpt-4o-2024-08-06",
)

print(result.annotated_path)
print(result.mask_path)
print(result.json_path)
print(result.confidence)
```

### 📄 Polygon JSON を確認

```bash
cat outputs/<name>_polygon.json
```

### 🧱 典型的な出力ファイル

```text
outputs/
├─ <base>_<timestamp>_annotated.png
├─ <base>_<timestamp>_mask.png
└─ <base>_<timestamp>_polygon.json
```

## 🧠 開発メモ

- バックエンドフレームワーク: Tornado（`server.py`）。
- フロントエンド構成: 静的 HTML/CSS/JS（`templates/index.html`, `static/app.js`）。
- サービスワーカーはページ読み込み時に登録され、`static/sw.js` に列挙されたコアアセットをキャッシュします。
- ポリゴン検証では少なくとも 3 点を要求し、画像境界へクランプします。
- 出力生成には Pillow（`PIL.Image`, `ImageDraw`）を使用します。

ローカル開発のヒント:

```bash
# Run server
python server.py

# Run CLI against an existing image
python segment_organoid.py 6f1e1874eacffe1dbae0393f48811e74.jpg
```

## 🩺 トラブルシューティング

- `openai.AuthenticationError` などが発生する場合:
  - Python を実行しているシェルで `OPENAI_API_KEY` が設定されているか確認してください。
- `Model response did not contain valid JSON`:
  - 別モデルを試すか再実行してください。フォールバック解析は実装済みですが、不正形式の出力では失敗する可能性があります。
- `Polygon must contain at least 3 points`:
  - モデルが無効なポリゴンを返しています。より鮮明な画像で再試行してください。
- UI は表示されるが分割に失敗する場合:
  - `/api/segment` が返した例外種別をサーバーログで確認してください。
- `ModuleNotFoundError`:
  - 有効化中の環境で `pip install -r requirements.txt` を再実行してください。

## 🛣️ ロードマップ

このリポジトリの想定される次のステップ:

1. ポリゴン検証と出力生成の自動テストを追加する。
2. CI（lint、型チェック、スモークテスト）を追加する。
3. ディレクトリ単位処理向けのバッチモード CLI を追加する。
4. 複数オブジェクトマスクまたはインスタンス分割出力をサポートする。
5. Dockerfile とデプロイ手順ドキュメントを追加する。
6. ベンチマーク例と期待出力付きサンプルデータセットを追加する。
7. `i18n/` 配下の多言語 README を完成させる。

## 🤝 コントリビューション

コントリビューションを歓迎します。

推奨ワークフロー:

1. リポジトリを Fork し、機能ブランチを作成します。
2. 変更は焦点を絞り、明確なコミットメッセージを付けます。
3. ローカルで Web + CLI の手動フローを検証します。
4. 振る舞いの変更点とテスト証跡を記載した Pull Request を作成します。

推奨されるコントリビューション領域:
- より安定したポリゴン抽出のためのプロンプト設計改善。
- フロントエンド可視化の改善（ズーム/パン、輪郭スムージング）。
- テストハーネスと再現可能なサンプルフィクスチャ。
- ドキュメントとローカライゼーションの改善。

## 📄 ライセンス

現在、このリポジトリにはライセンスファイルが存在しません。

前提: ライセンスが明示的に追加されるまでは、デフォルトで all rights reserved です。

このプロジェクトを共有または配布する予定がある場合は、`LICENSE` ファイルを追加し、このセクションを更新してください。
